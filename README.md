# dl_basic
overview
研究生图形学方向，比较熟悉最优传输理论（Optimal Transport Theory），记录下dl相关学习的经验。

我认为deep learning和传统的算法学习路径区别很大，随着这几年的发展，已经几乎完全是一个工程问题。

在我一开始看李沐的《动手学深度学习》https://zh.d2l.ai/ 我感觉很像c++ primer，超级宝典，大而全。但是如果你是工作之后的学习，基本上没可能从头到尾学一边。
1，是战线太长了，我们都想做低成本，高收益的事情。学个一年，我觉得基本上很难坚持下去。沐神这个书教育性质，实在是太大而全了，普通人没那么多精力
2，做事情要有的放矢。你得先锚定一个目标，向着问题出发，找到一个最短路径，直接开写代码去跑。

step1
书大致过一遍，基础概念，哪些任务，每个任务是啥，咋解决，有个概念直接上手。参考：https://zhuanlan.zhihu.com/p/400628805 把神经网络基础每个环节都敲一遍。
这个过程你一定要结合自己的需求和有经验的人去沟通，多research。举个栗子，你要是搞自动驾驶轨迹预测，21年之前大家还都在gnn搞个半天，随着后面退出factorzed attn之后，基本上就淘汰了，也别花时间去研究gnn。

step2
完成之后，直接找到你要做的方向，看看综述或者别人的总结，把sota论文找出来，多看看自己写一个报告，深入去思考一下。然后直接找到几个论文，有代码的，把代码搞出来直接去环境搭起来，跑一跑，理解理解。结合着源码+gpt，去扣torch语法，注意积累。

step3


踩的坑：
1，凡事莫求全，千万别大而全的看很多课和视频，除非你就是要Broaden your horizons，还是我说的那句，深度学习现在就是一个工程问题，最重要就是上手。基础的backbone，网络，预训练权重，训练框架都非常完善了，就像小马过河，你不下水根本不知道有多深。
2，别纯看理论，那理论有时候就是为了自洽，说的天花乱坠，一看代码可能就是a+b。^_^... 这真的和传统算法区别很大，这就讲究一个work就ok。
3，torch的语法要多练，特别是tensor的操作，要多实践，哪个维度需要增加，复制，哪个维度需要删除，都是根据具体场景来的，多写比看几篇文章体会深入的多。



